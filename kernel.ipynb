{
  "cells": [
    {
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom pandas.api.types import CategoricalDtype\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nfrom sklearn import model_selection, ensemble, metrics, linear_model\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import *\nimport os\nbase_dir = '../input'\nprint(os.listdir(base_dir))\n\n\n# Any results you write to the current directory are saved as output.https://www.kaggle.com/wanermiranda/linear-regression-ml-tp1?scriptVersionId=5240484",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "df_diamonds = pd.read_csv('%s/diamonds.csv'%(base_dir), index_col='Unnamed: 0')\ndf_diamonds.head(10)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "877abad593a3e39cd4e76d7dbad18288dae62e08"
      },
      "cell_type": "markdown",
      "source": "## Numeric Features \n* Carat: weight of the diamond\n* depth: depth %  The height of a diamond, measured from the culet to the table, divided by its average girdle diameter\n* table: table % The width of the diamond's table expressed as a percentage of its average diameter\n* price: the price of the diamond\n* xlength: mm\n* ywidth: mm\n* zdepth: mm"
    },
    {
      "metadata": {
        "_uuid": "98385ec227afd7a3f5ff08073ffc07795d54785e",
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "df_diamonds.describe()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5ee6d1d43b7eff5db4be04ee0c292367c50d160d"
      },
      "cell_type": "markdown",
      "source": "## cut \nDescribe cut quality of the diamond. Quality in increasing order Fair, Good, Very Good, Premium, Ideal"
    },
    {
      "metadata": {
        "_uuid": "787f5714a8636051ff3874ec45c7f7c10c060b75",
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "cuts_ordered = ['Fair',\n                'Good',\n                'Very Good',\n                'Premium',\n                'Ideal']\ndf_diamonds['cut'] = df_diamonds['cut'].astype(CategoricalDtype(cuts_ordered, ordered=True))\nprint(df_diamonds['cut'].unique())\ndf_diamonds['cut'].describe()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "4210c64cd66c7200e888b8198781070dc99c6542"
      },
      "cell_type": "markdown",
      "source": "## color\nmColor of the diamond, with D being the best and J the worst"
    },
    {
      "metadata": {
        "_uuid": "027047bb1b67635c3487c2d01a92603dc8abfc3a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "colors_ordered = [  'J',\n                    'I',\n                    'H',\n                    'G',\n                    'F',\n                    'E',\n                    'D']\ndf_diamonds['color'] = df_diamonds['color'].astype(CategoricalDtype(colors_ordered, ordered=True))\nprint(df_diamonds['color'].unique())\ndf_diamonds['color'].describe()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f3a28f822e662d4a4bfd60408d2547e62e670047"
      },
      "cell_type": "markdown",
      "source": "## clarity\nHow obvious inclusions are within the diamond:(in order from best to worst, FL = flawless, I3= level 3 inclusions) FL,IF, VVS1, VVS2, VS1, VS2, SI1, SI2, I1, I2, I3"
    },
    {
      "metadata": {
        "_uuid": "3b1bfb5329e161298d386c5310c1a78cb46974fa",
        "trusted": true
      },
      "cell_type": "code",
      "source": "clarity_codes = {'I3',\n'I2',\n'I1',\n'SI2',\n'SI1',\n'VS2',\n'VS1',\n'VVS2',\n'VVS1',\n'IF',\n'FL'}\ndf_diamonds['clarity'] = df_diamonds['clarity'].astype(CategoricalDtype(clarity_codes, ordered=True))\nprint(df_diamonds['clarity'].unique())\ndf_diamonds['clarity'].describe()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ff600d5845d90675104880a893d97727c81e990e"
      },
      "cell_type": "markdown",
      "source": "## Cleaning the Data\nThere are some zero dimensions for the diamonds, since that must be noise or mistype, we are cleaning it.\n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "12857a643f144df6f855a07a82e6c80a4d7720bd"
      },
      "cell_type": "code",
      "source": "df_diamonds = df_diamonds.drop(df_diamonds.loc[df_diamonds.x <= 0].index)\ndf_diamonds = df_diamonds.drop(df_diamonds.loc[df_diamonds.y <= 0].index)\ndf_diamonds = df_diamonds.drop(df_diamonds.loc[df_diamonds.z <= 0].index)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "23d38491d85c45459fe2b582f1b460c9dfa76891"
      },
      "cell_type": "markdown",
      "source": "## Handcraft features\nSince the measures for the diamond follow a 3d shape, we are considering here some handcraft features. \nVolume for the diamond = reflecting its size and weight. \nRatio between the X, Y and Z.\n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f14e6c21aa6070199e551fcaab1bd3e248591ad7"
      },
      "cell_type": "code",
      "source": "df_diamonds['volume'] = df_diamonds['x'] * df_diamonds['y'] * df_diamonds['z']\ndf_diamonds['ratio'] = df_diamonds['x'] / df_diamonds['y']\ndf_diamonds['ratio'] = df_diamonds['x'] / df_diamonds['z']\ndf_diamonds.head(10)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d9fd0904b92ed37e3febcd2fd79e1e56339de40b",
        "trusted": true
      },
      "cell_type": "code",
      "source": "train, test_reserved = model_selection.train_test_split(df_diamonds, test_size=0.2, random_state=42)\ntest_reserved.to_csv('test.csv')\ntrain.to_csv('train.csv')\n# test_reserved = pd.read_csv('test.csv', index_col='Unnamed: 0')\n# train = pd.read_csv('train.csv', index_col='Unnamed: 0')\ndf_diamonds = train",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "40aa323183c465324b80d853e8078f98861d1cb6"
      },
      "cell_type": "markdown",
      "source": "# Distribution Overview\nThe prices seems to follow a power law curve, as show bellow in the graph. "
    },
    {
      "metadata": {
        "_uuid": "631192439fb586987bb4b0dbe6ab86cab9688264",
        "trusted": true
      },
      "cell_type": "code",
      "source": "df_diamonds['price'].hist(bins=100)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "cd3f5d223b0fd5d22c1f20efac39206928b9356e",
        "trusted": true
      },
      "cell_type": "code",
      "source": "df_diamonds['price'].describe()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "633be5cf172d1162ebb0c25799d24dc9a93a21c2"
      },
      "cell_type": "markdown",
      "source": "## SGD Regression For Fun\n"
    },
    {
      "metadata": {
        "_uuid": "64f46dea7e0ad812b0a31fb32dad8e1b1033f4f4",
        "trusted": true
      },
      "cell_type": "code",
      "source": "cat_columns = df_diamonds.select_dtypes(['category']).columns.values\ndf_diamonds[cat_columns] = df_diamonds[cat_columns].apply(lambda x: x.cat.codes)\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "7a5882811ccd8819456a7eba412305d5c03b80e9"
      },
      "cell_type": "markdown",
      "source": "## Normalizing the Data\nUsing the robust scaller **to not only use the mean normalization**, but also to be less vulnerable to outliers."
    },
    {
      "metadata": {
        "_uuid": "4e961645520c3d8c27f8975ba6e78a0dd2ca1d1a",
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "X  = df_diamonds.copy()\ny = X.pop('price')\nscaler = RobustScaler()\nscaler.fit(X)\nX = scaler.transform(X)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ac3b7f88def624b3ff237cfbe2321091c8559886"
      },
      "cell_type": "markdown",
      "source": "## Regression\nSince there is no negative values in the prices we are using here the log(price) to maintain this domain during the regression train. \nWe are also using a 5 cross fold validation to do the grid search. \n\nA validation set was extracted from the data as a simulation for the test set.\n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5ec10ea5e85d3356e8594bedb4e5292dbae376b7"
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import *\n\nX_train, X_val, y_train, y_val = model_selection.train_test_split(X, y, test_size=0.1, random_state=42)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ed88474e913c58b94b3b7b70c6a99dd9769b2b83",
        "trusted": true
      },
      "cell_type": "code",
      "source": "\n    \nparams = {\n    'learning_rate':['invscaling', 'optimal'],\n    'eta0': [0.1, 0.05, 0.01], \n    'max_iter':[20000]\n}\n\nscoring = {\n    'NEG_MSE': 'neg_mean_squared_error',\n    'NEG_MAE': 'neg_mean_absolute_error',\n    'VARIANCE': 'r2'\n}\n\nbest_params = {'eta0': [0.01], 'learning_rate': ['invscaling'], 'max_iter': [10000]}\nbest_params_ = {'eta0': 0.01, 'learning_rate': 'invscaling', 'max_iter': 10000}\n\n## Removing the penalty because it could lead to throubles\n## when implementing the regression\nregr = linear_model.SGDRegressor(**best_params_, penalty=None, verbose=True) \n# regr_ = GridSearchCV(regr_, best_params, cv=2,\n#                        scoring=scoring, refit='VARIANCE',\n#                     n_jobs=-1,\n#                    verbose=True\n#                    )\n\n#regr = GridSearchCV(linear_model.SGDRegressor(),params,cv=3, scoring=scoring, refit='VARIANCE', n_jobs=-1, verbose=True)\n\nregr.fit(X_train, np.log(y_train))\n# results = regr.cv_results_\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "49d3838ff0763e3ef739ce6476d5acf274626b8d"
      },
      "cell_type": "code",
      "source": "# regr.best_score_",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b8fcfe10618eddce897beb586ab26b66c9f4a5bf"
      },
      "cell_type": "code",
      "source": "# regr.best_params_",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "trusted": true,
        "_uuid": "422a8684ca2e3a34f9e8f4e7796d337c3febafe7"
      },
      "cell_type": "code",
      "source": "# def GridSearch_table_plot(grid_clf, param_name,score,\n#                           num_results=15,                          \n#                           negative=True,\n#                           graph=True,\n#                           display_all_params=True):\n\n#     '''Display grid search results\n\n#     Arguments\n#     ---------\n\n#     grid_clf           the estimator resulting from a grid search\n#                        for example: grid_clf = GridSearchCV( ...\n\n#     param_name         a string with the name of the parameter being tested\n\n#     num_results        an integer indicating the number of results to display\n#                        Default: 15\n\n#     negative           boolean: should the sign of the score be reversed?\n#                        scoring = 'neg_log_loss', for instance\n#                        Default: True\n\n#     graph              boolean: should a graph be produced?\n#                        non-numeric parameters (True/False, None) don't graph well\n#                        Default: True\n\n#     display_all_params boolean: should we print out all of the parameters, not just the ones searched for?\n#                        Default: True\n\n#     Usage\n#     -----\n\n#     GridSearch_table_plot(grid_clf, \"min_samples_leaf\")\n\n#                           '''\n#     from matplotlib      import pyplot as plt\n#     from IPython.display import display\n#     import pandas as pd\n\n#     clf = grid_clf.best_estimator_\n#     clf_params = grid_clf.best_params_\n#     if negative:\n#         clf_score = -grid_clf.best_score_\n#     else:\n#         clf_score = grid_clf.best_score_\n#     clf_stdev = grid_clf.cv_results_['std_test_'+score][grid_clf.best_index_]\n#     cv_results = grid_clf.cv_results_\n\n#     print(\"best parameters: {}\".format(clf_params))\n#     print(\"best score:      {:0.5f} (+/-{:0.5f})\".format(clf_score, clf_stdev))\n#     if display_all_params:\n#         import pprint\n#         pprint.pprint(clf.get_params())\n\n#     # pick out the best results\n#     # =========================\n#     scores_df = pd.DataFrame(cv_results).sort_values(by='rank_test_'+score)\n\n#     best_row = scores_df.iloc[0, :]\n#     if negative:\n#         best_mean = -best_row['mean_test_'+score]\n#     else:\n#         best_mean = best_row['mean_test_'+score]\n#     best_stdev = best_row['std_test_'+score]\n#     best_param = best_row['param_' + param_name]\n\n#     # display the top 'num_results' results\n#     # =====================================\n#     display(pd.DataFrame(cv_results) \\\n#             .sort_values(by='rank_test_'+score).head(num_results))\n\n#     # plot the results\n#     # ================\n#     scores_df = scores_df.sort_values(by='param_' + param_name)\n\n#     if negative:\n#         means = -scores_df['mean_test_'+score]\n#     else:\n#         means = scores_df['mean_test_'+score]\n#     stds = scores_df['std_test_'+score]\n#     params = scores_df['param_' + param_name]\n\n    \n# GridSearch_table_plot(regr, param_name=\"eta0\", score='VARIANCE', negative=False)        ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true,
        "_uuid": "7a33c45874de8f198989d343f407320d24b4b674"
      },
      "cell_type": "code",
      "source": "# regr.best_estimator_",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "839e38e291f09bf8ea0bf46b1403121ac95804f9",
        "trusted": true
      },
      "cell_type": "code",
      "source": "y_val.describe()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6d3ed27c572307c9ebf1a6172efef9e09ccfd4f6"
      },
      "cell_type": "code",
      "source": "y_pred = np.exp(regr.predict(X_val))\npd.Series(y_pred).describe()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0522010985023ed087796f90d5db4d0a43f3912b",
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(\"MSE: %.3f\" % metrics.mean_squared_error(y_val, y_pred))\nprint(\"MAE: %.3f\" % metrics.mean_absolute_error(y_val, y_pred))\nprint('R2: %.3f' % metrics.r2_score(y_val, y_pred))\n\nplt.hist(y_val, bins=100, color='blue', linewidth=3)\nplt.show()\nplt.hist(y_pred, bins=100, color='red', linewidth=3)\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "36fd43759e56554db0c8e3f1b53df6aeea7d4c95",
        "trusted": true
      },
      "cell_type": "code",
      "source": "df = pd.DataFrame({'real': y_val, 'pred': y_pred})\nax = df.sort_values('real').plot.scatter('real', 'pred', figsize=(5, 5))\n_ = ax.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=3)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "9dfc937025b0da986f7a5ad9dfe634d437ca00ea",
        "trusted": true
      },
      "cell_type": "code",
      "source": "def oneHotEncoding(features,columnName):\n\tcurrentCol = features.columns.get_loc(columnName)\n\tuniqueFeatures = features[columnName].unique()\n\tprint(uniqueFeatures)\n\tfor f in range(len(uniqueFeatures)):\n\t\tfeatures.insert(loc=currentCol+f,column=columnName+str(f),value=0)\n\t\tfeatures[columnName+str(f)][features[columnName]==uniqueFeatures[f]] = 1\n\t\t\n\tfeatures.pop(columnName)\n\ndef dummieCoding(features,columnName,orderedFeature):\n\tc = 0\n\tfor f in range(len(orderedFeature)):\n\t\tfeatures[columnName][features[columnName]==orderedFeature[f]] = 2**c\n\t\tc = c + 1",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "486ea6525308cc1ad2dc56654aad527014d2e860",
        "trusted": true
      },
      "cell_type": "code",
      "source": "def SMSE(parameters,features,target,j):\n\tnpFeatures = features.values\n\th = (np.sum(np.multiply(parameters,npFeatures))-target) * npFeatures[j]\n\treturn h\n\n\ndef SGD(alpha, iterations, features, target):\n\tfeatures.insert(0,\"theta0\",1)\n\tshape = features.shape\n\tnsamples = shape[0]\n\tprint(\"Number of samples: \"+str(nsamples))\n\tnparams = shape[1]\n\tprint(\"Number of parameters: \"+str(nparams))\n\n\tparameters = np.zeros(nparams)\n\tnew_parameters = np.zeros(nparams)\n\n\terror = 1\n\tepsilon = 0.0001\n\tit = 0\n\ti = 0\n\n\twhile ((error > epsilon) and (it < iterations) and (i < nsamples)):\n\t\tfor j in range(nparams):\n\t\t\tnew_parameters[j] = parameters[j] - alpha *             SMSE(parameters,features.ix[i],target.ix[i],j)\t\t\n\t\tit += 1\n\t\ti += 1\n\t\terror = math.sqrt(np.sum(np.power(np.subtract(new_parameters,parameters),2)))\n\t\tprint(parameters)\n\t\tprint(new_parameters)\n\t\tnp.copyto(parameters,new_parameters)\n\t\tprint(\"Epoch: \"+str(it))\n\t\tprint(\"Sample: \"+str(i))\n\t\tprint(\"Error: \"+str(error))\n\t\tprint(\"\\n\\n\")\n\n\tfeatures.pop(\"theta0\")\n\n\treturn parameters",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e46a79d263d96f3c889255b1415fb1c8ba8f1467"
      },
      "cell_type": "code",
      "source": "theta = np.array([1, 0, 1], dtype=np.double)\ntheta_temp = np.array([0, 0, 0], dtype=np.double)\ny = np.array([5.,10.], dtype=np.double)\nX = np.array([[0.,1., 2.],[0.,2., 3.]], dtype=np.double)\nprint (X)\nalpha = .01\nmax_iter = 50",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true,
        "_uuid": "97e1db86446eae07a972b9eb0d81fa75aed544dd"
      },
      "cell_type": "code",
      "source": "def hyphotesis(theta, X):\n    return np.sum(theta.T * X, axis=1)\n    \ndef MSE_theta(theta, X, y, alpha,j, h0, error):                \n        S = np.sum(np.matmul(error, X[:,j]))                \n        result = theta[j] - (alpha * (1. / len(y)) * S)        \n        return result\n\nfor i in range(max_iter):\n    h0 = hyphotesis(theta, X)\n    error = (h0 - y)\n    for j in range(X.shape[1]):\n        theta_temp[j] = MSE_theta(theta, X, y, alpha, j, h0, error)    \n        \n    theta = theta_temp.copy()\n    print (theta)    \n\nhyphotesis(theta, X)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3d9e0c1753391fe050a75359d8be53ad9684bcdf"
      },
      "cell_type": "code",
      "source": "import math\n\nimport math\n\n\ndef SGD_(alpha, max_iter, X, y):\n    \n    # Creating theta0 \n    X = np.insert(X, values=1, obj=0, axis=1)\n    \n    shape = X.shape\n    nsamples = shape[0]\n    print(\"Number of samples: \"+str(nsamples))\n    theta0 = np.zeros(nsamples)\n    nparams = shape[1]\n    print(\"Number of parameters: \"+str(nparams))\n\n\n    theta = np.random.uniform(size=nparams)\n    theta_temp = np.ones(nparams)\n\n    error = 1\n    epsilon = 0.001\n    it = 0\n    i = 0   \n    power_t = 0.25\n    t=1.0\n    \n    while ((error > epsilon) and (it < max_iter)):\n        h0 = hyphotesis(theta, X)\n        eta = alpha / pow(t, power_t)\n        error = (h0 - y)\n        for j in range(nparams):\n            theta_temp[j] = MSE_theta(theta, X, y, eta, j, h0, error)                \n        it += 1\n        i += 1\n        y_pred = hyphotesis(theta_temp, X)\n#         print (y,hyphotesis(theta_temp, X))\n        error =  ((y - y_pred) ** 2).mean() / 2 \n#         print(theta)\n#         print(theta_temp)\n\n        theta = theta_temp.copy()\n        \n        if (i % 100) == 0 or i == 1:\n            print(\"Epoch: %s Batch: %s Error: %.8f lr: %.8f \"%(it, i, error, eta))\n        t += 1            \n   \n    return theta\ndef predict(theta, X):\n    X = np.insert(X, values=1, obj=0, axis=1)\n    return hyphotesis(theta_h, X)\n\nmax_iter = 10000\ntheta_h = SGD_(alpha, max_iter, X, y)\nprint (y,predict(theta_h, X))\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "trusted": true,
        "_uuid": "f12b2d1321c703975d08f97db37c9cb3677c458a"
      },
      "cell_type": "code",
      "source": "max_iter = 10000\ntheta_h = SGD_(1., max_iter=max_iter, X=X_train, y=np.log(y_train.values))\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "36dc9621a15f9bf1aab6eb11600f31b5e379f252"
      },
      "cell_type": "code",
      "source": "y_pred = np.exp(predict(theta_h, X_val))\n\ndf = pd.DataFrame({'real': y_val, 'pred': y_pred})\nax = df.sort_values('real').plot.scatter('real', 'pred', figsize=(5, 5))\n_ = ax.plot([y_val.min(), y_val.max()], [y_pred.min(), y_pred.max()], 'k--', lw=3)\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "95b777cdd28ea30d7ce6b722db63208000e0f00a"
      },
      "cell_type": "code",
      "source": "np.mean((np.log(y_pred) - np.log(y_val.values))**2)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8445b674ec0ce22a184fa0f05f9bdde285c86775"
      },
      "cell_type": "code",
      "source": "np.mean((y_pred - y_val.values)**2)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4b0979fdde25217dcf481a705d5ca2bf968ee67f"
      },
      "cell_type": "code",
      "source": "print(\"MSE: %.3f\" % metrics.mean_squared_error(y_val, y_pred))\nprint(\"MAE: %.3f\" % metrics.mean_absolute_error(y_val, y_pred))\nprint('R2: %.3f' % metrics.r2_score(y_val, y_pred))\n\nplt.hist(y_val, bins=100, color='blue', linewidth=3)\nplt.show()\nplt.hist(y_pred, bins=100, color='red', linewidth=3)\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3b63be911e02ac50d52eb24e44d71785d9c75eb4"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}